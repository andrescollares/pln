{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorio de Introducci√≥n al Procesamiento de Lenguaje Natural\n",
        "\n",
        "### Contexto\n",
        "\n",
        "El objetivo de este laboratorio es introducirlos a la construcci√≥n de clasificadores, probando y comparando diferentes m√©todos.\n",
        "\n",
        "### Entrega\n",
        "Lo que deber√°n entregar es un archivo *.ipynb* con su soluci√≥n, que incluya c√≥digo, discusiones y conclusiones del trabajo. \n",
        "\n",
        "‚ö†Ô∏è Es importante que en el archivo a entregar est√©n **las salidas de cada celda ya ejecutadas** ‚ö†Ô∏è. \n",
        "\n",
        "En caso de hacer el ejercicio 3, opcional, deber√°n entregar tambi√©n un archivo .csv **correctamente formateado** con las predicciones de sus modelos.\n",
        "\n",
        "El plazo m√°ximo es el **21 de octubre a las 23:59 horas.**\n",
        "\n",
        "### Plataforma sugerida\n",
        "Sugerimos que utilicen la plataforma [Google colab](https://colab.research.google.com/), que permite trabajar colaborativamente con un *notebook* de python. Al finalizar pueden descargar ese *notebook* en un archivo .ipynb, incluyendo las salidas ya ejecutadas, con la opci√≥n ```File -> Download -> Download .ipynb```\n",
        "\n",
        "### Instalaci√≥n de bibliotecas\n",
        "Antes de empezar, ejecuten esta celda para instalar las dependencias üëá"
      ],
      "metadata": {
        "id": "-4azOYi8KSoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn\n",
        "!pip install gensim\n",
        "!pip install spacy\n",
        "!pip install nltk"
      ],
      "metadata": {
        "id": "_7FpsJWGszpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ejercicio 1 - Primer contacto con el corpus\n",
        "\n",
        "Lo primero a hacer es cargar el corpus. Hay muchas formas de hacerlo ([por ejemplo con Pandas](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)), pero la m√°s sencilla es utilizando funcionalidades nativas de python. El resultado ser√° una lista de n-uplas, donde cada una de ellas se correpondes a una fila del .csv (incluso el cabezal, la primera l√≠nea).\n",
        "\n",
        "üßê**¬øQu√© tienen que hacer?**ü§î \n",
        "Carguen a Colab los archivos necesarios del corpus usando el panel de la izquierda y luego ejecuten las siguientes celdas. Ajusten lo necesario para cargar todo el conjunto de *train* (`train_1.csv` y `train_2.csv`), el de dev y tambi√©n sus anotaciones, que van a ser un subconjunto del archivo `train_1.csv`."
      ],
      "metadata": {
        "id": "sAumcYFLP0f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "\"\"\"\n",
        "  Completen con su c√≥digo de carga de archivos \"train\" y \"dev\" ac√°\n",
        "\"\"\"\n",
        "\n",
        "with open('train_2.csv', newline='') as corpus_csv:\n",
        "  reader = csv.reader(corpus_csv)\n",
        "  next(reader) # Saltea el cabezal del archivo\n",
        "  train_set = [x for x in reader]\n",
        "\n",
        "with open('dev.csv', newline='') as corpus_csv:\n",
        "  reader = csv.reader(corpus_csv)\n",
        "  next(reader) # Saltea el cabezal del archivo\n",
        "  dev_set = [x for x in reader]"
      ],
      "metadata": {
        "id": "nnBJGtH5QLcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimamos alg√∫n tweet aleatorio a ver si se carg√≥ bien."
      ],
      "metadata": {
        "id": "S5vw6mqiNbgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Elegir un tweet aleatorio e imprimirlo junto a su categor√≠a\n",
        "random_tweet = random.choice(dev_set)\n",
        "print(f\"El tweet es: {random_tweet[1]}\")\n",
        "print(f\"y su categor√≠a: {random_tweet[2]}\")"
      ],
      "metadata": {
        "id": "ldfWPEtCNebS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 1.1 - Composici√≥n de los conjuntos de entrenamiento y desarrollo\n",
        "\n",
        "Para ver c√≥mo esta compuesto el corpus, van a hacer una recorrida sobre todos los tweets en √©l y contar cu√°ntos ejemplos hay de cada categor√≠a. Examinen, discutan y comparen la cantidad de ejemplos en cada categor√≠a, en *train* y en *dev* ¬øhay m√°s ejemplos de unas categor√≠as que de otras? ¬øtienen la misma proporci√≥n en *train* y *dev*?\n",
        "\n",
        "üßê**¬øQu√© tienen que hacer?**ü§î Recorran los conjuntos, saquen conclusiones y escr√≠banlas en una celda de texto, a continuaci√≥n."
      ],
      "metadata": {
        "id": "3HFf4BwD36uZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Completen con su c√≥digo ac√°\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RNBy_qybD_oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 1.2 - C√°lculo del acuerdo entre anotadores\n",
        "\n",
        "A continuaci√≥n queremos ver cu√°n de acuerdo estuvieron grupalmente con las anotaciones originales. Para eso deber√°n usar [esta funci√≥n disponible en sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html#sklearn.metrics.cohen_kappa_score).\n",
        "\n",
        "üßê**¬øQu√© tienen que hacer?**ü§î  Calculen el grado de acuerdo entre las antoaciones originales y las suyas como grupo. "
      ],
      "metadata": {
        "id": "VVPMAnvaJkXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Completen con su c√≥digo ac√°\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GIwwIOilECnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 2 - Experimentos con clasificadores\n",
        "\n",
        "Ahora que cargaron y examinaron los datos, van a crear un primer clasificador para resolver el problema autom√°ticamente. Como los clasificadores asumen que sus atributos son num√©ricos, hay que encontrar primero una forma num√©rica de representar los textos. En este ejercicio van a experimentar con varias formas de hacer eso.\n",
        "\n",
        "En todas las partes podr√°n usar cualquiera de los clasificadores disponibles en el cat√°logo de modelos de [aprendizaje supervisado de sklearn](https://scikit-learn.org/stable/supervised_learning.html).  "
      ],
      "metadata": {
        "id": "NRniq2WASeTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Parte 2.1 - Bag of Words\n",
        "\n",
        "El primer experimento es utilizando Bag of Words (BoW) para representar los textos. Ac√° les dejamos un ejemplo, pero prueben con las diferentes configuraciones que admite [CountVectorizer de sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) y con los modelos que quieran del [cat√°logo de sklearn](https://scikit-learn.org/stable/supervised_learning.html). Tambi√©n pueden explorar diferentes formas de limpieza de los textos. \n",
        "\n",
        "Midan el aprendizaje sobre *dev* con la m√©trica [$F_1$, con la implementaci√≥n de sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html). Tambi√©n pueden usar otras m√©tricas adicionales; queda a su disposici√≥n.\n",
        "\n",
        "üßê**¬øQu√© tienen que hacer?**ü§î Hagan varios experimentos con diferentes tipos de clasificadores y diferentes configuraciones de BoW para vectorizar. Midan el aprendizajen con $F_1$. Discutan, reflexionen y escriban las conclusiones en una celda de texto a continuaci√≥n."
      ],
      "metadata": {
        "id": "YZMlbsw2uFLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Completen con su c√≥digo ac√°\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "bow_vectorizer = CountVectorizer() # Vectorizador \"bag of words\"\n",
        "clf = MultinomialNB() # El clasificador es un Naive Bayes. Prueben ac√° con varios modelos\n",
        "\n",
        "training_features = bow_vectorizer.fit_transform([x[1] for x in train_set]) # Se vectorizan los tweets de train\n",
        "clf.fit(training_features, [x[2] for x in train_set]) # Se entrena el clasificador usando los tweets vectorizados\n",
        "\n",
        "dev_features = bow_vectorizer.transform([x[1] for x in dev_set]) # Se vectorizan los tweets de dev\n",
        "prediction = clf.predict(dev_features) # Se predicen las categor√≠as de cada tweet (ya vectorizado en la l√≠nea anterior)\n",
        "\n",
        "print(\"F-Score: \" + str(round(f1_score([x[2] for x in dev_set], prediction, average='macro')*100, 2))) # Se imprime la medida F\n",
        "\n"
      ],
      "metadata": {
        "id": "G9BNltLduHqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 2.2 - TF-iDF\n",
        "\n",
        "El segundo es utilizando TF-iDF (Term Frequency - inverse Document Frequency) para representar los textos.\n",
        "\n",
        "üßê**¬øQu√© tienen que hacer?**ü§î Lo an√°logo a la parte anterior pero probando diferentes configuraciones con [TF-iDF de sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Comparen los resultados de $F_1$ con los obtenidos para Bag of Words y escriban las conclusiones en una celda de texto a continuaci√≥n."
      ],
      "metadata": {
        "id": "74o3beG-_tCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Completen con su c√≥digo ac√°\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vgTQJXL_D42e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 2.3 - Word embeddings\n",
        "\n",
        "El tercer y √∫ltimo enfoque es utilizando **vectores de palabras est√°ticos** para representar los textos. Hay much√≠simas colecciones de vectores de palabras, pero en esta ocasi√≥n vamos a usar unos entrenados por la Univerisdad de Chile. \n",
        "\n",
        "Una idea simple pero √∫til para representar un tweet puede ser hallar el centroide de los vectores relacionados a las palabras que aparecen en √©l, y luego comparar cu√°l es m√°s similar a cu√°l. \n",
        "\n",
        "üßê**¬øQu√© tienen que hacer?**ü§î Lo an√°logo a las partes anteriores pero probando con una representaci√≥n basada en *embeddings*. Comparen con $F_1$, saquen conclusiones y escr√≠banlas."
      ],
      "metadata": {
        "id": "wIPSS06GDV-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Les dejamos el siguiente c√≥digo de ejemplo. Permite cargar los vectores, hallar el centroide de una lista de tokens y calcular las similitudes entre diferentes centroides."
      ],
      "metadata": {
        "id": "sIg11w8rGCAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Se descargan los vectores\n",
        "!wget -q http://dcc.uchile.cl/~jperez/word-embeddings/fasttext-sbwc.100k.vec.gz\n",
        "!gzip -d -q fasttext-sbwc.100k.vec.gz\n",
        "!ls\n",
        "\n",
        "# Se crea el objeto\n",
        "vectors = KeyedVectors.load_word2vec_format('fasttext-sbwc.100k.vec')\n",
        "\n",
        "# Unos ejemplos, ya tokenizados\n",
        "example_1 = [\"Qu√©\", \"tremendo\", \"d√≠a\", \"hace\"]\n",
        "example_2 = [\"Qu√©\", \"lindo\", \"d√≠a\", \"hace\"]\n",
        "example_3 = [\"Hace\", \"un\", \"precioso\", \"d√≠a\"]\n",
        "example_4 = [\"Hoy\", \"est√°\", \"lindo\", \"el\", \"d√≠a\"]\n",
        "example_5 = [\"Pah\", \"esta\", \"milanesa\", \"con\", \"mayonesa\", \"est√°\", \"buen√≠sima\"]\n",
        "example_6 = [\"Ya\", \"le\", \"dije\", \"que\", \"le\", \"vas\", \"a\", \"escribir\"]\n",
        "\n",
        "# Se calculan los centroides\n",
        "centroid_example_1 = np.mean([vectors[word.lower()] for word in example_1], axis=0)\n",
        "centroid_example_2 = np.mean([vectors[word.lower()] for word in example_2], axis=0)\n",
        "centroid_example_3 = np.mean([vectors[word.lower()] for word in example_3], axis=0)\n",
        "centroid_example_4 = np.mean([vectors[word.lower()] for word in example_4], axis=0)\n",
        "centroid_example_5 = np.mean([vectors[word.lower()] for word in example_5], axis=0)\n",
        "centroid_example_6 = np.mean([vectors[word.lower()] for word in example_6], axis=0)\n",
        "\n",
        "# Se imprime la similitud entre los centroides del ejemplo 1 y el resto. \n",
        "print(cosine_similarity([centroid_example_1],[centroid_example_1]))\n",
        "print(cosine_similarity([centroid_example_1],[centroid_example_2]))\n",
        "print(cosine_similarity([centroid_example_1],[centroid_example_3]))\n",
        "print(cosine_similarity([centroid_example_1],[centroid_example_4]))\n",
        "print(cosine_similarity([centroid_example_1],[centroid_example_5]))\n",
        "print(cosine_similarity([centroid_example_1],[centroid_example_6]))\n",
        "\n"
      ],
      "metadata": {
        "id": "6MlhUYqidBvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Completen con su c√≥digo ac√°\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xS-TBgmIEU3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 3 (opcional)\n",
        "\n",
        "Esta √∫ltima parte es **opcional**. Ahora que vieron c√≥mo crear clasificadores, invitamos a que intenten construir el mejor clasificador posible utilizando estos enfoques o cualquier otro. Pueden probar lo que quieran, desde enfoques por reglas, utilizando POS-tagging, an√°lisis sint√°ctico, an√°lisis morfol√≥gico o listas de palabras, a modelos neuronales como BERT.\n",
        "\n",
        "Si realizan esta parte opcional, tendr√°n que entregar en EVA las predicciones para un archivo de *test* que subiremos pr√≥ximo a la entrega. Los grupos que obtengan las 3 mejores medidas al evaluar en el conjunto de test ganar√°n 5 puntos porcentuales que sumar√°n para la nota final del curso.\n",
        "\n",
        "üßê**¬øQu√© tienen que hacer?**ü§î Construir el mejor clasificador posible y subir a EVA las predicciones para *test*."
      ],
      "metadata": {
        "id": "U0uSp9-JH4EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Completen con su c√≥digo ac√°\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Bi2k9V9FD63d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}