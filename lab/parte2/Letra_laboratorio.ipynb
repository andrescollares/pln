{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4azOYi8KSoC"
      },
      "source": [
        "# Laboratorio de Introducción al Procesamiento de Lenguaje Natural\n",
        "\n",
        "### Contexto\n",
        "\n",
        "El objetivo de este laboratorio es introducirlos a la construcción de clasificadores, probando y comparando diferentes métodos.\n",
        "\n",
        "### Entrega\n",
        "Lo que deberán entregar es un archivo *.ipynb* con su solución, que incluya código, discusiones y conclusiones del trabajo. \n",
        "\n",
        "⚠️ Es importante que en el archivo a entregar estén **las salidas de cada celda ya ejecutadas** ⚠️. \n",
        "\n",
        "En caso de hacer el ejercicio 3, opcional, deberán entregar también un archivo .csv **correctamente formateado** con las predicciones de sus modelos.\n",
        "\n",
        "El plazo máximo es el **21 de octubre a las 23:59 horas.**\n",
        "\n",
        "### Plataforma sugerida\n",
        "Sugerimos que utilicen la plataforma [Google colab](https://colab.research.google.com/), que permite trabajar colaborativamente con un *notebook* de python. Al finalizar pueden descargar ese *notebook* en un archivo .ipynb, incluyendo las salidas ya ejecutadas, con la opción ```File -> Download -> Download .ipynb```\n",
        "\n",
        "### Instalación de bibliotecas\n",
        "Antes de empezar, ejecuten esta celda para instalar las dependencias 👇"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/andres/fing/nsql/lab2/.venv/bin/python\n"
          ]
        }
      ],
      "source": [
        "!which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_7FpsJWGszpa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from sklearn) (1.1.2)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.22.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.9.2)\n",
            "Requirement already satisfied: gensim in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from gensim) (1.22.3)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from gensim) (1.9.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: spacy in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (3.4.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (1.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (59.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (1.22.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: jinja2 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (8.1.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (1.9.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from spacy) (3.0.7)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.0.8)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\n",
            "Requirement already satisfied: nltk in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from nltk) (2022.9.13)\n",
            "Requirement already satisfied: click in /home/andres/fing/nsql/lab2/.venv/lib/python3.10/site-packages (from nltk) (8.1.3)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install sklearn\n",
        "!python -m pip install gensim\n",
        "!python -m pip install spacy\n",
        "!python -m pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAumcYFLP0f8"
      },
      "source": [
        "#Ejercicio 1 - Primer contacto con el corpus\n",
        "\n",
        "Lo primero a hacer es cargar el corpus. Hay muchas formas de hacerlo ([por ejemplo con Pandas](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)), pero la más sencilla es utilizando funcionalidades nativas de python. El resultado será una lista de n-uplas, donde cada una de ellas se correpondes a una fila del .csv (incluso el cabezal, la primera línea).\n",
        "\n",
        "🧐**¿Qué tienen que hacer?**🤔 \n",
        "Carguen a Colab los archivos necesarios del corpus usando el panel de la izquierda y luego ejecuten las siguientes celdas. Ajusten lo necesario para cargar todo el conjunto de *train* (`train_1.csv` y `train_2.csv`), el de dev y también sus anotaciones, que van a ser un subconjunto del archivo `train_1.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nnBJGtH5QLcA"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "\"\"\"\n",
        "  Completen con su código de carga de archivos \"train\" y \"dev\" acá\n",
        "\"\"\"\n",
        "\n",
        "with open('tweets_grupo_D_1.csv', newline='') as corpus_csv:\n",
        "  reader = csv.reader(corpus_csv)\n",
        "  next(reader) # Saltea el cabezal del archivo\n",
        "  original_annotations = [x for x in reader]\n",
        "\n",
        "with open('train_1.csv', newline='') as corpus_csv:\n",
        "  reader = csv.reader(corpus_csv)\n",
        "  next(reader) # Saltea el cabezal del archivo\n",
        "  train_set = [x for x in reader]\n",
        "\n",
        "with open('train_2.csv', newline='') as corpus_csv:\n",
        "  reader = csv.reader(corpus_csv)\n",
        "  next(reader) # Saltea el cabezal del archivo\n",
        "  train_set = train_set + [x for x in reader] \n",
        "\n",
        "with open('dev.csv', newline='') as corpus_csv:\n",
        "  reader = csv.reader(corpus_csv)\n",
        "  next(reader) # Saltea el cabezal del archivo\n",
        "  dev_set = [x for x in reader]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5vw6mqiNbgD"
      },
      "source": [
        "Imprimamos algún tweet aleatorio a ver si se cargó bien."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ldfWPEtCNebS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El tweet es: #NotreDameEnLlamas Un idiota culpando a los islamistas sin pruebas y haciendo fotomontajes. Otro idiota diciendo que el que te duela lo de notre dame quiere decir que no nos duele el hambre en el mundo. Twitter está plagada de imbéciles !!\n",
            "y su categoría: anger\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# Elegir un tweet aleatorio e imprimirlo junto a su categoría\n",
        "random_tweet = random.choice(dev_set)\n",
        "print(f\"El tweet es: {random_tweet[1]}\")\n",
        "print(f\"y su categoría: {random_tweet[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HFf4BwD36uZ"
      },
      "source": [
        "## Parte 1.1 - Composición de los conjuntos de entrenamiento y desarrollo\n",
        "\n",
        "Para ver cómo esta compuesto el corpus, van a hacer una recorrida sobre todos los tweets en él y contar cuántos ejemplos hay de cada categoría. Examinen, discutan y comparen la cantidad de ejemplos en cada categoría, en *train* y en *dev* ¿hay más ejemplos de unas categorías que de otras? ¿tienen la misma proporción en *train* y *dev*?\n",
        "\n",
        "🧐**¿Qué tienen que hacer?**🤔 Recorran los conjuntos, saquen conclusiones y escríbanlas en una celda de texto, a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RNBy_qybD_oY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set length: 5723\n",
            "Dev set length: 1250\n",
            "Train set tweet amount by category:\n",
            "{   'anger': 563,\n",
            "    'disgust': 103,\n",
            "    'fear': 63,\n",
            "    'joy': 1230,\n",
            "    'others': 2786,\n",
            "    'sadness': 733,\n",
            "    'surprise': 245}\n",
            "Dev set tweet amount by category:\n",
            "{   'anger': 150,\n",
            "    'disgust': 27,\n",
            "    'fear': 14,\n",
            "    'joy': 259,\n",
            "    'others': 617,\n",
            "    'sadness': 131,\n",
            "    'surprise': 52}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "print(f\"Train set length: {len(train_set)}\")\n",
        "print(f\"Dev set length: {len(dev_set)}\")\n",
        "\n",
        "# Contar cuántos ejemplos hay de cada catergoría\n",
        "# Train\n",
        "train_set_categories = [tweet[2] for tweet in train_set]\n",
        "\n",
        "category_names = set(train_set_categories)\n",
        "\n",
        "train_set_categories_count = dict.fromkeys(category_names, 0)\n",
        "\n",
        "for category in train_set_categories:\n",
        "    train_set_categories_count[category] += 1\n",
        "\n",
        "print(\"Train set tweet amount by category:\")\n",
        "pp.pprint(train_set_categories_count)\n",
        "\n",
        "# Dev\n",
        "dev_set_categories = [tweet[2] for tweet in dev_set]\n",
        "\n",
        "category_names = set(dev_set_categories)\n",
        "\n",
        "dev_set_categories_count = dict.fromkeys(category_names, 0)\n",
        "\n",
        "for category in dev_set_categories:\n",
        "    dev_set_categories_count[category] += 1\n",
        "\n",
        "print(\"Dev set tweet amount by category:\")\n",
        "pp.pprint(dev_set_categories_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aunque hay mas ejemplos de una que de otras, esto es esperable dado que el tamaño del conjunto de \"\"\"**Dev**\"\"\" (no se como se llama en realidad) es más pequeño que el de train. Lo importante es que la distribución de los datos sea similar y como se puede observar en el resultado de la celda de código, la distribución es similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set distribution\n",
            "[0.1, 0.49, 0.13, 0.01, 0.21, 0.04, 0.02]\n",
            "Dev set distribution\n",
            "[0.01, 0.12, 0.49, 0.1, 0.04, 0.21, 0.02]\n"
          ]
        }
      ],
      "source": [
        "print(\"Train set distribution\")\n",
        "pp.pprint([round(value/len(train_set),2) for value in train_set_categories_count.values()])\n",
        "print(\"Dev set distribution\")\n",
        "pp.pprint([round(value/len(dev_set),2) for value in dev_set_categories_count.values()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVPMAnvaJkXA"
      },
      "source": [
        "## Parte 1.2 - Cálculo del acuerdo entre anotadores\n",
        "\n",
        "A continuación queremos ver cuán de acuerdo estuvieron grupalmente con las anotaciones originales. Para eso deberán usar [esta función disponible en sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html#sklearn.metrics.cohen_kappa_score).\n",
        "\n",
        "🧐**¿Qué tienen que hacer?**🤔  Calculen el grado de acuerdo entre las antoaciones originales y las suyas como grupo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GIwwIOilECnH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.401386263390044"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "original_annotations_categories = [annotation[2] for annotation in original_annotations]\n",
        "train_set_categories = [annotation[2] for annotation in train_set[600:800]]\n",
        "\n",
        "cohen_kappa_score(original_annotations_categories, train_set_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRniq2WASeTt"
      },
      "source": [
        "# Ejercicio 2 - Experimentos con clasificadores\n",
        "\n",
        "Ahora que cargaron y examinaron los datos, van a crear un primer clasificador para resolver el problema automáticamente. Como los clasificadores asumen que sus atributos son numéricos, hay que encontrar primero una forma numérica de representar los textos. En este ejercicio van a experimentar con varias formas de hacer eso.\n",
        "\n",
        "En todas las partes podrán usar cualquiera de los clasificadores disponibles en el catálogo de modelos de [aprendizaje supervisado de sklearn](https://scikit-learn.org/stable/supervised_learning.html).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZMlbsw2uFLm"
      },
      "source": [
        "## Parte 2.1 - Bag of Words\n",
        "\n",
        "El primer experimento es utilizando Bag of Words (BoW) para representar los textos. Acá les dejamos un ejemplo, pero prueben con las diferentes configuraciones que admite [CountVectorizer de sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) y con los modelos que quieran del [catálogo de sklearn](https://scikit-learn.org/stable/supervised_learning.html). También pueden explorar diferentes formas de limpieza de los textos. \n",
        "\n",
        "Midan el aprendizaje sobre *dev* con la métrica [$F_1$, con la implementación de sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html). También pueden usar otras métricas adicionales; queda a su disposición.\n",
        "\n",
        "🧐**¿Qué tienen que hacer?**🤔 Hagan varios experimentos con diferentes tipos de clasificadores y diferentes configuraciones de BoW para vectorizar. Midan el aprendizajen con $F_1$. Discutan, reflexionen y escriban las conclusiones en una celda de texto a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9BNltLduHqB"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "  Completen con su código acá\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "bow_vectorizer = CountVectorizer() # Vectorizador \"bag of words\"\n",
        "clf = MultinomialNB() # El clasificador es un Naive Bayes. Prueben acá con varios modelos\n",
        "\n",
        "training_features = bow_vectorizer.fit_transform([x[1] for x in train_set]) # Se vectorizan los tweets de train\n",
        "clf.fit(training_features, [x[2] for x in train_set]) # Se entrena el clasificador usando los tweets vectorizados\n",
        "\n",
        "dev_features = bow_vectorizer.transform([x[1] for x in dev_set]) # Se vectorizan los tweets de dev\n",
        "prediction = clf.predict(dev_features) # Se predicen las categorías de cada tweet (ya vectorizado en la línea anterior)\n",
        "\n",
        "print(\"F-Score: \" + str(round(f1_score([x[2] for x in dev_set], prediction, average='macro')*100, 2))) # Se imprime la medida F\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74o3beG-_tCq"
      },
      "source": [
        "## Parte 2.2 - TF-iDF\n",
        "\n",
        "El segundo es utilizando TF-iDF (Term Frequency - inverse Document Frequency) para representar los textos.\n",
        "\n",
        "🧐**¿Qué tienen que hacer?**🤔 Lo análogo a la parte anterior pero probando diferentes configuraciones con [TF-iDF de sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Comparen los resultados de $F_1$ con los obtenidos para Bag of Words y escriban las conclusiones en una celda de texto a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgTQJXL_D42e"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "  Completen con su código acá\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIPSS06GDV-J"
      },
      "source": [
        "## Parte 2.3 - Word embeddings\n",
        "\n",
        "El tercer y último enfoque es utilizando **vectores de palabras estáticos** para representar los textos. Hay muchísimas colecciones de vectores de palabras, pero en esta ocasión vamos a usar unos entrenados por la Univerisdad de Chile. \n",
        "\n",
        "Una idea simple pero útil para representar un tweet puede ser hallar el centroide de los vectores relacionados a las palabras que aparecen en él, y luego comparar cuál es más similar a cuál. \n",
        "\n",
        "🧐**¿Qué tienen que hacer?**🤔 Lo análogo a las partes anteriores pero probando con una representación basada en *embeddings*. Comparen con $F_1$, saquen conclusiones y escríbanlas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIg11w8rGCAN"
      },
      "source": [
        "\n",
        "Les dejamos el siguiente código de ejemplo. Permite cargar los vectores, hallar el centroide de una lista de tokens y calcular las similitudes entre diferentes centroides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MlhUYqidBvR"
      },
      "outputs": [],
      "source": [
        "from numpy.linalg import norm\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Se descargan los vectores\n",
        "!wget -q http://dcc.uchile.cl/~jperez/word-embeddings/fasttext-sbwc.100k.vec.gz\n",
        "!gzip -d -q fasttext-sbwc.100k.vec.gz\n",
        "!ls\n",
        "\n",
        "# Se crea el objeto\n",
        "vectors = KeyedVectors.load_word2vec_format('fasttext-sbwc.100k.vec')\n",
        "\n",
        "# Unos ejemplos, ya tokenizados\n",
        "example_1 = [\"Qué\", \"tremendo\", \"día\", \"hace\"]\n",
        "example_2 = [\"Qué\", \"lindo\", \"día\", \"hace\"]\n",
        "example_3 = [\"Hace\", \"un\", \"precioso\", \"día\"]\n",
        "example_4 = [\"Hoy\", \"está\", \"lindo\", \"el\", \"día\"]\n",
        "example_5 = [\"Pah\", \"esta\", \"milanesa\", \"con\", \"mayonesa\", \"está\", \"buenísima\"]\n",
        "example_6 = [\"Ya\", \"le\", \"dije\", \"que\", \"le\", \"vas\", \"a\", \"escribir\"]\n",
        "\n",
        "# Se calculan los centroides\n",
        "centroid_example_1 = np.mean([vectors[word.lower()] for word in example_1], axis=0)\n",
        "centroid_example_2 = np.mean([vectors[word.lower()] for word in example_2], axis=0)\n",
        "centroid_example_3 = np.mean([vectors[word.lower()] for word in example_3], axis=0)\n",
        "centroid_example_4 = np.mean([vectors[word.lower()] for word in example_4], axis=0)\n",
        "centroid_example_5 = np.mean([vectors[word.lower()] for word in example_5], axis=0)\n",
        "centroid_example_6 = np.mean([vectors[word.lower()] for word in example_6], axis=0)\n",
        "\n",
        "# Se imprime la similitud entre los centroides del ejemplo 1 y el resto. \n",
        "print(cosine_similarity([centroid_example_1],[centroid_example_1]))\n",
        "print(cosine_similarity([centroid_example_1],[centroid_example_2]))\n",
        "print(cosine_similarity([centroid_example_1],[centroid_example_3]))\n",
        "print(cosine_similarity([centroid_example_1],[centroid_example_4]))\n",
        "print(cosine_similarity([centroid_example_1],[centroid_example_5]))\n",
        "print(cosine_similarity([centroid_example_1],[centroid_example_6]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS-TBgmIEU3R"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "  Completen con su código acá\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0uSp9-JH4EN"
      },
      "source": [
        "# Ejercicio 3 (opcional)\n",
        "\n",
        "Esta última parte es **opcional**. Ahora que vieron cómo crear clasificadores, invitamos a que intenten construir el mejor clasificador posible utilizando estos enfoques o cualquier otro. Pueden probar lo que quieran, desde enfoques por reglas, utilizando POS-tagging, análisis sintáctico, análisis morfológico o listas de palabras, a modelos neuronales como BERT.\n",
        "\n",
        "Si realizan esta parte opcional, tendrán que entregar en EVA las predicciones para un archivo de *test* que subiremos próximo a la entrega. Los grupos que obtengan las 3 mejores medidas al evaluar en el conjunto de test ganarán 5 puntos porcentuales que sumarán para la nota final del curso.\n",
        "\n",
        "🧐**¿Qué tienen que hacer?**🤔 Construir el mejor clasificador posible y subir a EVA las predicciones para *test*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi2k9V9FD63d"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "  Completen con su código acá\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": ".venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
